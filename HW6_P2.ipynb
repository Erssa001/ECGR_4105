{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erssa001/ECGR_4105/blob/main/HW6_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAFTpNZUe8fp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a82ce4-8eb4-4a63-e35f-7705551f866a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bddd0ea6af0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxxY55ZIfzrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121e996b-7ce0-4108-e9a0-cbdc479a59a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch7/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 57173507.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data-unversioned/p1ch7/cifar-10-python.tar.gz to ../data-unversioned/p1ch7/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaqcaxpsXSTK"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)\n",
        "\n",
        "seq_single = nn.Sequential(\n",
        "  nn.Linear(3072, 512),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(512, 10),\n",
        "  nn.LogSoftmax(dim=1))\n",
        "\n",
        "seq_multi = nn.Sequential(\n",
        "  nn.Linear(3072, 512),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(512, 256),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(256, 128),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(128, 10),\n",
        "  nn.LogSoftmax(dim=1))\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_epochs = 300\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "optimizer_single = optim.SGD(seq_single.parameters(), lr=learning_rate)\n",
        "optimizer_multi = optim.SGD(seq_multi.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJclp73l-16I",
        "outputId": "47483006-3c22-4c1d-d1d5-5851a357fe08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 1.9932\n",
            "Epoch 10, Loss 1.4383\n",
            "Epoch 20, Loss 1.3204\n",
            "Epoch 30, Loss 0.6231\n",
            "Epoch 40, Loss 0.2488\n",
            "Epoch 50, Loss 0.4303\n",
            "Epoch 60, Loss 0.1493\n",
            "Epoch 70, Loss 0.0435\n",
            "Epoch 80, Loss 0.0510\n",
            "Epoch 90, Loss 0.0451\n",
            "Epoch 100, Loss 0.0472\n",
            "Epoch 110, Loss 0.0339\n",
            "Epoch 120, Loss 0.0152\n",
            "Epoch 130, Loss 0.0191\n",
            "Epoch 140, Loss 0.0267\n",
            "Epoch 150, Loss 0.0139\n",
            "Epoch 160, Loss 0.0150\n",
            "Epoch 170, Loss 0.0145\n",
            "Epoch 180, Loss 0.0138\n",
            "Epoch 190, Loss 0.0261\n",
            "Epoch 200, Loss 0.0082\n",
            "Epoch 210, Loss 0.0106\n",
            "Epoch 220, Loss 0.0128\n",
            "Epoch 230, Loss 0.0067\n",
            "Epoch 240, Loss 0.0109\n",
            "Epoch 250, Loss 0.0082\n",
            "Epoch 260, Loss 0.0061\n",
            "Epoch 270, Loss 0.0066\n",
            "Epoch 280, Loss 0.0070\n",
            "Epoch 290, Loss 0.0067\n",
            "Epoch 300, Loss 0.0097\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  for imgs, labels in train_loader:\n",
        "\n",
        "    batch_size = imgs.shape[0]\n",
        "    outputs = seq_single(imgs.view(batch_size, -1))\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    optimizer_single.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_single.step()\n",
        "\n",
        "  if ((epoch == 1) or (epoch % 10 == 0)):\n",
        "    print(f\"Epoch {epoch}, Loss {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NayRWHQ-6_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c61121-3dda-4290-ad45-4ebf46c7877e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 1.6575\n",
            "Epoch 10, Loss 1.3371\n",
            "Epoch 20, Loss 1.0627\n",
            "Epoch 30, Loss 0.6645\n",
            "Epoch 40, Loss 0.3956\n",
            "Epoch 50, Loss 0.2582\n",
            "Epoch 60, Loss 0.0182\n",
            "Epoch 70, Loss 0.2774\n",
            "Epoch 80, Loss 0.0017\n",
            "Epoch 90, Loss 0.0012\n",
            "Epoch 100, Loss 0.0017\n",
            "Epoch 110, Loss 0.0014\n",
            "Epoch 120, Loss 0.0025\n",
            "Epoch 130, Loss 0.0009\n",
            "Epoch 140, Loss 0.0014\n",
            "Epoch 150, Loss 0.0010\n",
            "Epoch 160, Loss 0.0011\n",
            "Epoch 170, Loss 0.0004\n",
            "Epoch 180, Loss 0.0007\n",
            "Epoch 190, Loss 0.0004\n",
            "Epoch 200, Loss 0.0004\n",
            "Epoch 210, Loss 0.0007\n",
            "Epoch 220, Loss 0.0004\n",
            "Epoch 230, Loss 0.0005\n",
            "Epoch 240, Loss 0.0003\n",
            "Epoch 250, Loss 0.0003\n",
            "Epoch 260, Loss 0.0005\n",
            "Epoch 270, Loss 0.0004\n",
            "Epoch 280, Loss 0.0003\n",
            "Epoch 290, Loss 0.0007\n",
            "Epoch 300, Loss 0.0005\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  for imgs, labels in train_loader:\n",
        "\n",
        "    batch_size = imgs.shape[0]\n",
        "    outputs = seq_multi(imgs.view(batch_size, -1))\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    optimizer_multi.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_multi.step()\n",
        "\n",
        "  if ((epoch == 1) or (epoch % 10 == 0)):\n",
        "    print(f\"Epoch {epoch}, Loss {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nBVKzovHEbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871f86f5-c4f7-451c-c6bb-e4e459b9b61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Layer Training Accuracy: 1.000000\n",
            "Single Layer Validation Accuracy: 0.472900\n",
            "Multi Layer Training Accuracy: 1.000000\n",
            "Multi Layer Validation Accuracy: 0.454400\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in train_loader:\n",
        "    outputs = seq_single(imgs.view(imgs.shape[0], -1))\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    total += labels.shape[0]\n",
        "    correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Single Layer Training Accuracy: %f\" % (correct / total))\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in val_loader:\n",
        "    outputs = seq_single(imgs.view(imgs.shape[0], -1))\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    total += labels.shape[0]\n",
        "    correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Single Layer Validation Accuracy: %f\" % (correct / total))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in train_loader:\n",
        "    outputs = seq_multi(imgs.view(imgs.shape[0], -1))\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    total += labels.shape[0]\n",
        "    correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Multi Layer Training Accuracy: %f\" % (correct / total))\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64, shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in val_loader:\n",
        "    outputs = seq_multi(imgs.view(imgs.shape[0], -1))\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    total += labels.shape[0]\n",
        "    correct += int((predicted == labels).sum())\n",
        "\n",
        "print(\"Multi Layer Validation Accuracy: %f\" % (correct / total))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2A5AaITOn4i/AKxLg/+yf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}